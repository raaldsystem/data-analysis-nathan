# -*- coding: utf-8 -*-
"""pakistan-large-dataprep-nathangerald.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YlizjiQP_r1QoBTNCEakoNeYpj6_hbel

# Project RevoU : Analisis Data Pakistan Large E-commerce

**Idea**: The anomaly in the number of canceled orders was 34% in the period 2016 to 2018

**Question**: What factors might be related to this anomaly?"

* How to *increase the number of completed orders by 15%* in the next 1 year by **minimizing the causes of order cancellations**


* How to reduce the number of canceled orders with a **cause-and-effect relationship**

**Final Statement : (Question)**

> How to increase the number of completed orders by 15% in the next 1 year by minimizing the causes of order cancellations and refunds

**Objective**

> To "increase the number of completed orders by 15%" within the next 1 year by minimizing the causes of order cancellations and refunds

**Scope**

>The data is collected from various largest retail e-commerce merchants in Pakistan

> Notes for 1 year from "1 January 2017 to 28 August 2018"

> The size of the data sample used is a database of e-commerce orders in Pakistan with a total of 448,348 rows and 25 columns of data"

# Import Library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import kagglehub

"""# Data Wrangling

# Gathering Data
"""

from google.colab import files
uploaded = files.upload()

pks_df = pd.read_csv('Pakistan Largest Ecommerce Dataset.csv', sep=",")
pks_df.head()

"""# Assesing Data"""

pks_df.info()

pks_df.isna().sum()

"""Insight :

* Column 21-25 can be determinate

# Cleaning Data

**REMOVE COLUMN 21-25**

pks_df = pks_df.drop(columns=["Unnamed: 21", "Unnamed: 22", "Unnamed: 23", "Unnamed: 24", "Unnamed: 25"])
"""

pks_df = pks_df.drop_duplicates()

pks_df.info()

print(pks_df.isnull().sum())
pks_df = pks_df.dropna()
print(pks_df.info())

pks_df['item_id'] = pks_df['item_id'].astype('Int64')
pks_df['created_at'] = pd.to_datetime(pks_df['created_at'], errors='coerce')
pks_df['qty_ordered'] = pks_df['qty_ordered'].astype('Int64')

pks_df['Year'] = pks_df['Year'].astype('Int64')
pks_df['Month'] = pks_df['Month'].astype('Int64')

pks_df['Customer ID'] = pks_df['Customer ID'].astype('Int64')

pks_df['increment_id'] = pd.to_numeric(pks_df['increment_id'], errors='coerce')
pks_df['Working Date'] = pd.to_datetime(pks_df['Working Date'], errors='coerce')
pks_df['Customer Since'] = pd.to_datetime(pks_df['Customer Since'], errors='coerce')
pks_df['M-Y'] = pd.to_datetime(pks_df['M-Y'], errors='coerce')
print(pks_df.info())

pks_df['Month'] = pks_df['Month'].astype(str)
pks_df.Month.replace((1,2,3,4,5,6,7,8,9,10,11,12),('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'), inplace=True)

pks_df['item_id'] = pks_df['item_id'].astype('object')
pks_df['Year'] = pks_df['Year'].astype('object')
pks_df['Customer ID'] = pks_df['Customer ID'].astype('object')

print(pks_df.info())

"""# Exploratory Data Analysis"""

pks_df.describe(include="all")

"""**DOWNLOAD DATA**"""

pks_df.to_csv('/content/cleaned_data.csv', index=False)
from google.colab import files
files.download('/content/cleaned_data.csv')

"""# **NEXT STEP = EXPLORATORY DATA ANALYSIS WITH EXCEL AND SQL!**"""